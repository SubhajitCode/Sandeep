{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "apply_transform = transforms.Compose([transforms.Resize(32), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.drop of            digit  label\n",
       "0        digit_0      1\n",
       "1        digit_1      4\n",
       "2        digit_2      2\n",
       "3        digit_3      3\n",
       "4        digit_4      1\n",
       "...          ...    ...\n",
       "1388  digit_1542      0\n",
       "1389  digit_1544      5\n",
       "1390  digit_1545      0\n",
       "1391  digit_1546      3\n",
       "1392  digit_1547      0\n",
       "\n",
       "[1393 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_file=\"data/labels.xls\"\n",
    "df=pd.read_excel(csv_file, header = None, names = [\"digit\", \"label\"])\n",
    "df.drop\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from os.path import isfile\n",
    "for index, row in df.iterrows():\n",
    "    img_name = \"data/\"+row[\"digit\"]+\".jpg\"\n",
    "    if(isfile(img_name)):\n",
    "        print(img_name)\n",
    "    else:\n",
    "        print(\"problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize=16\n",
    "from PIL import Image\n",
    "class BDRWdataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, trans=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.label_frame = pd.read_excel(csv_file, header = None, names = [\"digit\", \"label\"])\n",
    "        self.root_dir = root_dir\n",
    "        self.trans = trans\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name=self.root_dir+self.label_frame.iloc[idx, 0]+\".jpg\"\n",
    "        image = Image.open(img_name)\n",
    "        #image=image.convert(\"RGB\")\n",
    "        #image=image.resize(28,28)\n",
    "        label = (int(self.label_frame.iloc[idx, 1]))\n",
    "        image = self.trans(image)\n",
    "        sample = {\"image\": image, \"label\":label}\n",
    "        return sample\n",
    "    \n",
    "apply_transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor()])\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "dataset = BDRWdataset(csv_file = \"data/labels.xls\",\n",
    "                                    root_dir= \"data/\",\n",
    "                                    trans = apply_transform)\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [1100, 293])\n",
    "\n",
    "\n",
    "#train_set=dataset\n",
    "\n",
    "\n",
    "#BatchSize = 256 # change according to system specs\n",
    "\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset = train_set, batch_size=BatchSize,shuffle=True) \n",
    "testLoader = torch.utils.data.DataLoader(dataset = test_set, batch_size = BatchSize,shuffle = True)\n",
    "# Validation set with random rotations in the range [-90,90]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in train set: 1100\n",
      "LeNet(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1/100 : Training loss: 2.2940 | Training Accuracy: 15.4343\n",
      "Epoch 2/100 : Training loss: 2.2931 | Training Accuracy: 15.7215\n",
      "Epoch 3/100 : Training loss: 2.2920 | Training Accuracy: 15.7215\n",
      "Epoch 4/100 : Training loss: 2.2911 | Training Accuracy: 15.7215\n",
      "Epoch 5/100 : Training loss: 2.2901 | Training Accuracy: 15.7215\n",
      "Epoch 6/100 : Training loss: 2.2894 | Training Accuracy: 15.7215\n",
      "Epoch 7/100 : Training loss: 2.2884 | Training Accuracy: 15.7215\n",
      "Epoch 8/100 : Training loss: 2.2875 | Training Accuracy: 15.7215\n",
      "Epoch 9/100 : Training loss: 2.2867 | Training Accuracy: 15.7215\n",
      "Epoch 10/100 : Training loss: 2.2860 | Training Accuracy: 15.7215\n",
      "Epoch 11/100 : Training loss: 2.2850 | Training Accuracy: 15.7215\n",
      "Epoch 12/100 : Training loss: 2.2841 | Training Accuracy: 15.7215\n",
      "Epoch 13/100 : Training loss: 2.2831 | Training Accuracy: 15.7215\n",
      "Epoch 14/100 : Training loss: 2.2823 | Training Accuracy: 15.7215\n",
      "Epoch 15/100 : Training loss: 2.2812 | Training Accuracy: 15.7215\n",
      "Epoch 16/100 : Training loss: 2.2802 | Training Accuracy: 15.7215\n",
      "Epoch 17/100 : Training loss: 2.2790 | Training Accuracy: 15.7215\n",
      "Epoch 18/100 : Training loss: 2.2781 | Training Accuracy: 15.7215\n",
      "Epoch 19/100 : Training loss: 2.2767 | Training Accuracy: 15.7215\n",
      "Epoch 20/100 : Training loss: 2.2755 | Training Accuracy: 15.7215\n",
      "Epoch 21/100 : Training loss: 2.2742 | Training Accuracy: 15.7215\n",
      "Epoch 22/100 : Training loss: 2.2728 | Training Accuracy: 15.7215\n",
      "Epoch 23/100 : Training loss: 2.2715 | Training Accuracy: 15.7215\n",
      "Epoch 24/100 : Training loss: 2.2697 | Training Accuracy: 15.7215\n",
      "Epoch 25/100 : Training loss: 2.2682 | Training Accuracy: 15.7215\n",
      "Epoch 26/100 : Training loss: 2.2666 | Training Accuracy: 15.7215\n",
      "Epoch 27/100 : Training loss: 2.2652 | Training Accuracy: 15.7215\n",
      "Epoch 28/100 : Training loss: 2.2632 | Training Accuracy: 15.7215\n",
      "Epoch 29/100 : Training loss: 2.2614 | Training Accuracy: 15.7215\n",
      "Epoch 30/100 : Training loss: 2.2596 | Training Accuracy: 15.7215\n",
      "Epoch 31/100 : Training loss: 2.2577 | Training Accuracy: 15.7215\n",
      "Epoch 32/100 : Training loss: 2.2555 | Training Accuracy: 15.7215\n",
      "Epoch 33/100 : Training loss: 2.2533 | Training Accuracy: 15.7215\n",
      "Epoch 34/100 : Training loss: 2.2512 | Training Accuracy: 15.7215\n",
      "Epoch 35/100 : Training loss: 2.2488 | Training Accuracy: 15.7215\n",
      "Epoch 36/100 : Training loss: 2.2465 | Training Accuracy: 15.7215\n",
      "Epoch 37/100 : Training loss: 2.2441 | Training Accuracy: 15.7215\n",
      "Epoch 38/100 : Training loss: 2.2412 | Training Accuracy: 15.7215\n",
      "Epoch 39/100 : Training loss: 2.2390 | Training Accuracy: 15.7215\n",
      "Epoch 40/100 : Training loss: 2.2358 | Training Accuracy: 15.7215\n",
      "Epoch 41/100 : Training loss: 2.2328 | Training Accuracy: 15.7215\n",
      "Epoch 42/100 : Training loss: 2.2306 | Training Accuracy: 15.7215\n",
      "Epoch 43/100 : Training loss: 2.2273 | Training Accuracy: 15.7215\n",
      "Epoch 44/100 : Training loss: 2.2249 | Training Accuracy: 15.7215\n",
      "Epoch 45/100 : Training loss: 2.2218 | Training Accuracy: 15.7215\n",
      "Epoch 46/100 : Training loss: 2.2191 | Training Accuracy: 15.7215\n",
      "Epoch 47/100 : Training loss: 2.2165 | Training Accuracy: 15.7215\n",
      "Epoch 48/100 : Training loss: 2.2136 | Training Accuracy: 15.7215\n",
      "Epoch 49/100 : Training loss: 2.2110 | Training Accuracy: 15.7215\n",
      "Epoch 50/100 : Training loss: 2.2085 | Training Accuracy: 15.7215\n",
      "Epoch 51/100 : Training loss: 2.2062 | Training Accuracy: 15.7215\n",
      "Epoch 52/100 : Training loss: 2.2042 | Training Accuracy: 15.7215\n",
      "Epoch 53/100 : Training loss: 2.2019 | Training Accuracy: 15.7215\n",
      "Epoch 54/100 : Training loss: 2.2012 | Training Accuracy: 15.7215\n",
      "Epoch 55/100 : Training loss: 2.1987 | Training Accuracy: 15.7215\n",
      "Epoch 56/100 : Training loss: 2.1972 | Training Accuracy: 15.7215\n",
      "Epoch 57/100 : Training loss: 2.1966 | Training Accuracy: 15.7215\n",
      "Epoch 58/100 : Training loss: 2.1950 | Training Accuracy: 15.7215\n",
      "Epoch 59/100 : Training loss: 2.1933 | Training Accuracy: 15.7215\n",
      "Epoch 60/100 : Training loss: 2.1940 | Training Accuracy: 15.7215\n",
      "Epoch 61/100 : Training loss: 2.1930 | Training Accuracy: 15.7215\n",
      "Epoch 62/100 : Training loss: 2.1926 | Training Accuracy: 15.7215\n",
      "Epoch 63/100 : Training loss: 2.1911 | Training Accuracy: 15.7215\n",
      "Epoch 64/100 : Training loss: 2.1891 | Training Accuracy: 15.7215\n",
      "Epoch 65/100 : Training loss: 2.1882 | Training Accuracy: 15.7215\n",
      "Epoch 66/100 : Training loss: 2.1874 | Training Accuracy: 15.7215\n",
      "Epoch 67/100 : Training loss: 2.1867 | Training Accuracy: 15.7215\n",
      "Epoch 68/100 : Training loss: 2.1853 | Training Accuracy: 16.0086\n",
      "Epoch 69/100 : Training loss: 2.1844 | Training Accuracy: 16.5111\n",
      "Epoch 70/100 : Training loss: 2.1828 | Training Accuracy: 16.6547\n",
      "Epoch 71/100 : Training loss: 2.1811 | Training Accuracy: 16.8701\n",
      "Epoch 72/100 : Training loss: 2.1804 | Training Accuracy: 16.9419\n",
      "Epoch 73/100 : Training loss: 2.1786 | Training Accuracy: 17.1572\n",
      "Epoch 74/100 : Training loss: 2.1783 | Training Accuracy: 17.1572\n",
      "Epoch 75/100 : Training loss: 2.1764 | Training Accuracy: 17.1572\n",
      "Epoch 76/100 : Training loss: 2.1752 | Training Accuracy: 17.4444\n",
      "Epoch 77/100 : Training loss: 2.1743 | Training Accuracy: 17.6597\n",
      "Epoch 78/100 : Training loss: 2.1730 | Training Accuracy: 17.6597\n",
      "Epoch 79/100 : Training loss: 2.1717 | Training Accuracy: 17.7315\n",
      "Epoch 80/100 : Training loss: 2.1698 | Training Accuracy: 18.0187\n",
      "Epoch 81/100 : Training loss: 2.1680 | Training Accuracy: 18.4494\n",
      "Epoch 82/100 : Training loss: 2.1672 | Training Accuracy: 18.5212\n",
      "Epoch 83/100 : Training loss: 2.1646 | Training Accuracy: 18.6648\n",
      "Epoch 84/100 : Training loss: 2.1630 | Training Accuracy: 18.7365\n",
      "Epoch 85/100 : Training loss: 2.1608 | Training Accuracy: 18.8801\n",
      "Epoch 86/100 : Training loss: 2.1598 | Training Accuracy: 19.0955\n",
      "Epoch 87/100 : Training loss: 2.1571 | Training Accuracy: 19.3108\n",
      "Epoch 88/100 : Training loss: 2.1556 | Training Accuracy: 20.0287\n",
      "Epoch 89/100 : Training loss: 2.1540 | Training Accuracy: 20.7466\n",
      "Epoch 90/100 : Training loss: 2.1505 | Training Accuracy: 20.8902\n",
      "Epoch 91/100 : Training loss: 2.1493 | Training Accuracy: 21.0337\n",
      "Epoch 92/100 : Training loss: 2.1469 | Training Accuracy: 21.1773\n",
      "Epoch 93/100 : Training loss: 2.1441 | Training Accuracy: 21.4645\n",
      "Epoch 94/100 : Training loss: 2.1411 | Training Accuracy: 21.6080\n",
      "Epoch 95/100 : Training loss: 2.1390 | Training Accuracy: 21.7516\n",
      "Epoch 96/100 : Training loss: 2.1369 | Training Accuracy: 21.9670\n",
      "Epoch 97/100 : Training loss: 2.1325 | Training Accuracy: 22.0388\n",
      "Epoch 98/100 : Training loss: 2.1304 | Training Accuracy: 22.0388\n",
      "Epoch 99/100 : Training loss: 2.1274 | Training Accuracy: 21.9670\n",
      "Epoch 100/100 : Training loss: 2.1254 | Training Accuracy: 21.9670\n"
     ]
    }
   ],
   "source": [
    "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)        \n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 400)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "use_gpu = torch.cuda.is_available()\n",
    "net = LeNet()\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    print('GPU is avaialble!')\n",
    "    net = net.cuda()\n",
    "    \n",
    "    \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "learning_rate =10e-5\n",
    "num_epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "optimizer=optim.Adam(net.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0 \n",
    "    running_corr = 0\n",
    "        \n",
    "    for i,data in enumerate(trainLoader):\n",
    "        inputs,labels = data[\"image\"],data[\"label\"]\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(),labels.cuda() \n",
    "        # Initializing model gradients to zero\n",
    "        #net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # Data feed-forward through the network\n",
    "        outputs = net(inputs)\n",
    "        # Predicted class is the one with maximum probability\n",
    "        preds = torch.argmax(outputs,dim=1)\n",
    "        # Finding the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Accumulating the loss for each batch\n",
    "        running_loss += loss \n",
    "        # Accumulate number of correct predictions\n",
    "        running_corr += torch.sum(preds==labels)    \n",
    "        \n",
    "    totalLoss = running_loss/(i+1)\n",
    "    # Calculating gradients\n",
    "    totalLoss.backward()\n",
    "    # Updating the model parameters\n",
    "    optimizer.step()\n",
    "#     for f in net.parameters():\n",
    "#         f.data.sub_(f.grad.data * learning_rate)\n",
    "        \n",
    "    epoch_loss = running_loss.item()/(i+1)   #Total loss for one epoch\n",
    "    epoch_acc = running_corr.item()/1393\n",
    "    \n",
    "    \n",
    "         \n",
    "    train_loss.append(epoch_loss) #Saving the loss over epochs for plotting the graph\n",
    "    train_acc.append(epoch_acc) #Saving the accuracy over epochs for plotting the graph\n",
    "       \n",
    "        \n",
    "    print('Epoch {:.0f}/{:.0f} : Training loss: {:.4f} | Training Accuracy: {:.4f}'\n",
    "          .format(epoch+1,num_epochs,epoch_loss,epoch_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26973684210526316\n"
     ]
    }
   ],
   "source": [
    "accurate=0\n",
    "index=0\n",
    "for it,data in enumerate(testLoader):\n",
    "    with torch.no_grad():\n",
    "        image,label=data[\"image\"],data[\"label\"]\n",
    "        pred=net(image)\n",
    "        perd=torch.argmax(pred,dim=1)\n",
    "        accurate+=torch.sum(perd==label)\n",
    "        index=index+1\n",
    "accuracy=float(accurate)/(16*index)\n",
    "print(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
